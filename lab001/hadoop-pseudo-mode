#!/bin/bash
VERSION=1.0.4

if [ ! -x /usr/bin/add-apt-repository ]; then
  sudo apt-get -f -y install python-software-properties
fi
if [ ! -d /usr/lib/jvm/java-6-sun ]; then
  echo "---- [0.0] Installing Sun Java JDK 6 ........ ----"
  sudo add-apt-repository -y 'deb http://free.nchc.org.tw/debian squeeze non-free'
  sudo apt-get update
  cat << EOF | sudo /usr/bin/debconf-set-selections
sun-java6-bin   shared/accepted-sun-dlj-v1-1    select true
sun-java6-jdk   shared/accepted-sun-dlj-v1-1    select true
sun-java6-jre   shared/accepted-sun-dlj-v1-1    select true
EOF
  sudo apt-get -y --force-yes install sun-java6-jdk
  sudo add-apt-repository -r 'deb http://free.nchc.org.tw/debian squeeze non-free'
fi

if [ ! -d ${HOME}/hadoop ]; then
  if [ ! -f ${HOME}/hadoop-$VERSION.tar.gz ]; then
    echo "---- [0.1] Downloading Hadoop $VERSION ....... ----"
    wget -O ${HOME}/hadoop-$VERSION.tar.gz http://archive.apache.org/dist/hadoop/core/hadoop-$VERSION/hadoop-$VERSION.tar.gz
  fi
  echo "---- [0.2] Extracting Hadoop $VERSION ....... ----"
  tar zxvf ${HOME}/hadoop-$VERSION.tar.gz -C ${HOME}
  mv ${HOME}/hadoop-$VERSION ${HOME}/hadoop
  rm ${HOME}/hadoop-$VERSION.tar.gz
fi

if [ ! -d ${HOME}/hadoop/conf.local ]; then
  echo "---- [1.1] Generating Local Mode Configurations ....... ----"
  mv ${HOME}/hadoop/conf ${HOME}/hadoop/conf.local
  echo "export JAVA_HOME=/usr/lib/jvm/java-6-sun" >> ${HOME}/hadoop/conf.local/hadoop-env.sh
  echo "export HADOOP_HEAPSIZE=256" >> ${HOME}/hadoop/conf.local/hadoop-env.sh
fi

# Ignore the environment setting from $HADOOP_CONF_DIR
unset HADOOP_CONF_DIR

if [ ! -d ${HOME}/hadoop/conf.pseudo ]; then
  echo "---- [1.2] Generating Pseudo-Distributed Mode Configurations ....... ----"
  cp -R ${HOME}/hadoop/conf.local ${HOME}/hadoop/conf.pseudo
  cat > ${HOME}/hadoop/conf.pseudo/core-site.xml << EOF
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>${HOME}/hadoop/var/hadoop-\${user.name}</value>
  </property>
</configuration>
EOF
    cat > ${HOME}/hadoop/conf.pseudo/hdfs-site.xml << EOF
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
</configuration>
EOF
    cat > ${HOME}/hadoop/conf.pseudo/mapred-site.xml << EOF
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>
</configuration>
EOF
fi

if [ "$(pidof java)" != "" ]; then
  ${HOME}/hadoop/bin/hadoop-daemon.sh stop tasktracker
  ${HOME}/hadoop/bin/hadoop-daemon.sh stop datanode
  ${HOME}/hadoop/bin/hadoop-daemon.sh stop jobtracker
  ${HOME}/hadoop/bin/hadoop-daemon.sh stop namenode
  # wait for terminating java processes
  sleep 5
fi

if [ -e ${HOME}/hadoop/conf ]; then
  rm ${HOME}/hadoop/conf
fi

ln -s ${HOME}/hadoop/conf.pseudo ${HOME}/hadoop/conf

if [ ! -d ${HOME}/hadoop/var ]; then
  mkdir -p ${HOME}/hadoop/var
  chmod a+w ${HOME}/hadoop/var
fi

if [ ! -d ${HOME}/hadoop/var/hadoop-$(whoami)/dfs/name ]; then
  ${HOME}/hadoop/bin/hadoop namenode -format
fi

${HOME}/hadoop/bin/hadoop-daemon.sh start namenode
${HOME}/hadoop/bin/hadoop-daemon.sh start datanode
${HOME}/hadoop/bin/hadoop-daemon.sh start jobtracker
${HOME}/hadoop/bin/hadoop-daemon.sh start tasktracker
